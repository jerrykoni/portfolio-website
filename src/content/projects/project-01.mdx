---
title: Audio-Haptic VR Navigation
author: Your Name
description: A VR maze game built in Unity (Meta XR SDK) researching blind navigation. Awarded scholarship for top academic performance.
tags: ["Unity", "C#", "VR", "Accessibility", "Research"]
---

import BlockQuote from '@components/BlockQuote.astro'
import BreakoutImage from '@components/BreakoutImage.astro'
import { Image } from 'astro:assets'

## Project Overview

For my Master Thesis, I designed and developed a **Virtual Reality maze game** specifically for blind and low-vision users. The goal was to research how audio-haptic feedback can replace visual cues in 3D navigation.

**Tech Stack:** Unity, C#, Meta XR SDK, Oculus Quest.

<BreakoutImage src="/projects/project-image-1.png" />

## Technical Implementation

The core challenge was creating a navigation system that did not rely on sight. I engineered a custom C# system that translated spatial data into:
1.  **3D Spatial Audio:** Using HRTF (Head-Related Transfer Functions) to guide the user.
2.  **Haptic Feedback:** varying controller vibration patterns to indicate proximity to walls or objectives.

## User Testing & Results

I conducted user testing with **16 participants** to evaluate the effectiveness of the system. The data collected was analyzed to refine the navigation algorithms.

<div class="grid grid-cols-1 gap-4 md:grid-cols-2">
  <Image
    src="/projects/project-image-1.png"
    alt="VR Environment screenshot"
    width={1200}
    height={600}
    class="h-[250px] w-full rounded-lg object-cover"
  />
  <Image
    src="/projects/project-image-2.png"
    alt="Code snippet of Haptic logic"
    width={1200}
    height={600}
    class="h-[250px] w-full rounded-lg object-cover"
  />
</div>

<BlockQuote author="Thesis Conclusion">
  The research demonstrated that multi-sensory feedback significantly improves spatial awareness for non-visual navigation in virtual environments.
</BlockQuote>